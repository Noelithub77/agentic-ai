{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1) Installing dependencies:-"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install -q google-genai chromadb python-dotenv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2) Import and config:-"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from google import genai\n",
    "from google.genai import types\n",
    "import chromadb\n",
    "import numpy as np\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "GOOGLE_API_KEY = 'YOUR_API_KEY_HERE'\n",
    "client = genai.Client(api_key=GOOGLE_API_KEY)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3) Adding Your documents:- "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "documents = [\n",
    "    \"Python is a high-level programming language known for its simplicity.\",\n",
    "    \"JavaScript is primarily used for web development and interactive UIs.\",\n",
    "    \"Machine learning enables computers to learn from data without explicit programming.\",\n",
    "    \"React is a JavaScript library for building user interfaces.\",\n",
    "    \"Data science combines statistics, programming, and domain expertise.\"\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4) Embedding:-\n",
    "         > converts text to something mathematical that we can do math on and, vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_embedding_function(api_key, model_name=\"gemini-embedding-004\"):\n",
    "    client = genai.Client(api_key=api_key)\n",
    "    \n",
    "    def embedding_function(texts):\n",
    "        if isinstance(texts, str):\n",
    "            texts = [texts]\n",
    "        \n",
    "        response = client.models.embed_content(\n",
    "            model=model_name,\n",
    "            contents=texts\n",
    "        )\n",
    "        \n",
    "        return [embedding.values for embedding in response.embeddings]\n",
    "    \n",
    "    return embedding_function\n",
    "\n",
    "client = chromadb.Client()\n",
    "embedding_fn = create_embedding_function(\n",
    "    api_key=GOOGLE_API_KEY,\n",
    ")\n",
    "collection = client.get_or_create_collection(\n",
    "    name=\"documents\",\n",
    "    embedding_function=embedding_fn\n",
    ")\n",
    "\n",
    "for i, doc in enumerate(documents):\n",
    "    collection.add(\n",
    "        documents=[doc],\n",
    "        ids=[f\"doc_{i}\"]\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5) Querying:-\n",
    "            > via cosine similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def search_documents(query, n_results=2):\n",
    "    results = collection.query(\n",
    "        query_texts=[query],\n",
    "        n_results=n_results\n",
    "    )\n",
    "    return results['documents'][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6) LLM call:-"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_response(query, context):\n",
    "    prompt = f\"\"\"Answer the question based on the context below.\n",
    "\n",
    "Context:\n",
    "{context}\n",
    "\n",
    "Question: {query}\n",
    "\n",
    "Answer:\"\"\"\n",
    "    \n",
    "    response = client.models.generate_content(\n",
    "        model='gemini-2.5-flash-lite',\n",
    "        contents=prompt\n",
    "    )\n",
    "    return response.text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rag_query(query):\n",
    "    relevant_docs = search_documents(query)\n",
    "    context = \"\\n\".join(relevant_docs)\n",
    "    answer = generate_response(query, context)\n",
    "    \n",
    "    print(f\"Question: {query}\\n\")\n",
    "    print(f\"Context:\\n{context}\\n\")\n",
    "    print(f\"Answer:\\n{answer}\")\n",
    "    \n",
    "    return answer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# examples:-"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rag_query(\"What is Python?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rag_query(\"How does machine learning work?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rag_query(\"Tell me about React\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
